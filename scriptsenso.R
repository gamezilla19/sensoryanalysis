# PROJET ANALYSE SENSO - VERSION AVEC TRACKING ET MULTI-DATABASES
# Auteur: Version optimis√©e avec syst√®me de tracking et int√©gration multi-bases PostgreSQL
# Date: 2025-08-12

# ===== CHARGEMENT DES BIBLIOTH√àQUES =====
suppressPackageStartupMessages({
  library(tidyverse)
  library(readxl)
  library(agricolae)
  library(DBI)
  library(RPostgreSQL)
  library(RPostgres)      # Ajout pour meilleure compatibilit√©
  library(odbc)
  library(fs)
  library(writexl)
  library(stringr)
  library(digest)
})
# ===== FONCTION DE DIAGNOSTIC MISE √Ä JOUR =====
# ===== FONCTION DE DIAGNOSTIC MISE √Ä JOUR =====
debug_database_connections <- function() {
  cat("\nüîç DIAGNOSTIC COMPLET DES BASES DE DONN√âES\n")
  cat(paste(rep("=", 50), collapse = ""), "\n")
  
  # 1. Test connexion serveur
  cat("\n1. Test connexion serveur PostgreSQL...\n")
  con_server <- tryCatch({
    dbConnect(RPostgres::Postgres(),
              host = DB_CONFIG$host,
              port = DB_CONFIG$port,
              user = DB_CONFIG$user,
              password = DB_CONFIG$password,
              dbname = "postgres")
  }, error = function(e) {
    cat("‚ùå ERREUR serveur:", e$message, "\n")
    return(NULL)
  })
  
  if(is.null(con_server)) {
    cat("üö® ARR√äT: Impossible de se connecter au serveur PostgreSQL\n")
    return(FALSE)
  }
  
  cat("‚úÖ Connexion serveur OK\n")
  
  # 2. Lister les bases de donn√©es existantes
  cat("\n2. Bases de donn√©es existantes sur le serveur:\n")
  existing_dbs <- dbGetQuery(con_server, "SELECT datname FROM pg_database WHERE datistemplate = false;")
  for(db_name in existing_dbs$datname) {
    cat("  -", db_name, "\n")
  }
  
  # 3. V√©rifier chaque base de donn√©es n√©cessaire
  cat("\n3. V√©rification des bases de donn√©es n√©cessaires:\n")
  required_dbs <- c("SA_RAW_DATA", "SA_RESULTS_DATA", "SA_JUDGES", "SA_METADATA")
  
  for(db in required_dbs) {
    cat("\n--- Base de donn√©es:", db, "---\n")
    if(db %in% existing_dbs$datname) {
      cat("‚úÖ", db, "existe sur le serveur\n")
      
      # Test connexion √† cette base de donn√©es
      con_test <- create_db_connection(db)
      if(!is.null(con_test)) {
        cat("‚úÖ Connexion √†", db, "r√©ussie\n")
        
        # Lister les tables dans cette base de donn√©es
        tables <- dbListTables(con_test)
        if(length(tables) > 0) {
          cat("   Tables dans", db, ":", paste(tables, collapse = ", "), "\n")
          
          # Pour SA_RESULTS_DATA, v√©rifier les tables sp√©cialis√©es
          if(db == "SA_RESULTS_DATA") {
            expected_tables <- c("strengthandmo_results", "proximity_results", "triangulaire_results")
            for(expected_table in expected_tables) {
              if(expected_table %in% tables) {
                cat("   ‚úÖ", expected_table, "pr√©sente\n")
              } else {
                cat("   ‚ö†Ô∏è", expected_table, "manquante (sera cr√©√©e automatiquement)\n")
              }
            }
          }
          
          # Pour SA_METADATA, v√©rifier les tables sp√©cialis√©es
          if(db == "SA_METADATA") {
            expected_tables <- c("product_info", "test_info", "databrute")
            for(expected_table in expected_tables) {
              if(expected_table %in% tables) {
                cat("   ‚úÖ", expected_table, "pr√©sente\n")
              } else {
                cat("   ‚ö†Ô∏è", expected_table, "manquante (sera cr√©√©e automatiquement)\n")
              }
            }
          }
        } else {
          cat("   ‚ö†Ô∏è  Base", db, "vide (aucune table)\n")
        }
        safe_disconnect(con_test)
      } else {
        cat("‚ùå Impossible de se connecter √† la base", db, "\n")
      }
    } else {
      cat("‚ùå Base de donn√©es", db, "N'EXISTE PAS sur le serveur\n")
    }
  }
  
  safe_disconnect(con_server)
  return(TRUE)
}





# Lancer le diagnostic

debug_database_connections()


# ===== CONFIGURATION DES BASES DE DONN√âES =====
DB_CONFIG <- list(
  host = "emfrndsunx574.emea.sesam.mane.com",
  port = 5432,
  user = "dbadmin",
  password = "Azerty06*"
)

# Noms des bases de donn√©es
DATABASES <- list(
  RAW_DATA = "SA_RAW_DATA",
  RESULTS = "SA_RESULTS_DATA", 
  JUDGES = "SA_JUDGES",
  METADATA = "SA_METADATA"
)

# ===== FONCTIONS DE CONNEXION MULTI-DATABASES =====
create_db_connection <- function(database_name) {
  tryCatch({
    con <- dbConnect(RPostgres::Postgres(),
                     dbname = database_name,
                     host = DB_CONFIG$host,
                     port = DB_CONFIG$port,
                     user = DB_CONFIG$user,
                     password = DB_CONFIG$password)
    message("Connexion √©tablie √† la base : ", database_name)
    return(con)
  }, error = function(e) {
    message("ERREUR connexion √† ", database_name, " : ", e$message)
    return(NULL)
  })
}

safe_disconnect <- function(con) {
  if(!is.null(con) && dbIsValid(con)) {
    dbDisconnect(con)
  }
}

# ===== FONCTIONS DE CR√âATION DES TABLES =====
# ===== FONCTIONS DE CR√âATION DES TABLES CORRIG√âES =====

create_raw_data_table <- function(con) {
  
  if(is.null(con)) return(FALSE)
  
  
  
  tryCatch({
    
    # V√©rifier si la table existe d√©j√†
    
    if(dbExistsTable(con, "rawdata")) {
      
      message("Table rawdata existe d√©j√†")
      
      return(TRUE)
      
    }
    
    
    
    # Cr√©er la table rawdata avec des commandes s√©par√©es
    
    dbExecute(con, "CREATE TABLE IF NOT EXISTS rawdata (

      id SERIAL PRIMARY KEY,

      source_name VARCHAR(255) NOT NULL,

      trial_name VARCHAR(255),

      cj VARCHAR(100),

      product_name VARCHAR(255),

      attribute_name VARCHAR(255),

      nom_fonction VARCHAR(255),

      value NUMERIC,

      judge_status VARCHAR(50) DEFAULT 'conserved',

      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

      updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP

    )")
    
    
    
    # Cr√©er les index s√©par√©ment
    
    dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_rawdata_source ON rawdata(source_name)")
    
    dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_rawdata_trial ON rawdata(trial_name)")
    
    dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_rawdata_product ON rawdata(product_name)")
    
    
    
    message("Table rawdata cr√©√©e avec succ√®s")
    
    return(TRUE)
    
    
    
  }, error = function(e) {
    
    message("Erreur cr√©ation table rawdata : ", e$message)
    
    return(FALSE)
    
  })
  
}


# ===== FONCTIONS DE CR√âATION DES TABLES DE R√âSULTATS PAR TYPE =====

create_strength_results_table <- function(con) {
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    if(!dbExistsTable(con, "strengthandmo_results")) {  # ‚úÖ MINUSCULES
      dbExecute(con, "CREATE TABLE IF NOT EXISTS strengthandmo_results (
        id SERIAL PRIMARY KEY,
        source_name VARCHAR(255) NOT NULL,
        idtest VARCHAR(255),
        test_type VARCHAR(50),
        segment VARCHAR(500),
        segment_id INTEGER,
        product_name VARCHAR(255),
        classe VARCHAR(10),
        mean_value NUMERIC,
        sd_value NUMERIC,
        n_observations INTEGER,
        anova_5pct BOOLEAN,
        anova_10pct BOOLEAN,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )")
      
      # Cr√©er les index s√©par√©ment
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_strengthmo_source ON strengthandmo_results(source_name)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_strengthmo_type ON strengthandmo_results(test_type)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_strengthmo_product ON strengthandmo_results(product_name)")
      
      message("Table strengthandmo_results cr√©√©e avec succ√®s")
    }
    return(TRUE)
  }, error = function(e) {
    message("Erreur cr√©ation table strengthandmo_results : ", e$message)
    return(FALSE)
  })
}


create_proximity_results_table <- function(con) {
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    if(!dbExistsTable(con, "proximity_results")) {  # ‚úÖ MINUSCULES
      dbExecute(con, "CREATE TABLE IF NOT EXISTS proximity_results (
        id SERIAL PRIMARY KEY,
        source_name VARCHAR(255) NOT NULL,
        idtest VARCHAR(255),
        test_type VARCHAR(50),
        segment VARCHAR(500),
        segment_id INTEGER,
        product_name VARCHAR(255),
        classe VARCHAR(10),
        mean_value NUMERIC,
        sd_value NUMERIC,
        n_observations INTEGER,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )")
      
      # Cr√©er les index s√©par√©ment
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_proximity_source ON proximity_results(source_name)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_proximity_type ON proximity_results(test_type)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_proximity_product ON proximity_results(product_name)")
      
      message("Table proximity_results cr√©√©e avec succ√®s")
    }
    return(TRUE)
  }, error = function(e) {
    message("Erreur cr√©ation table proximity_results : ", e$message)
    return(FALSE)
  })
}


create_triangular_results_table <- function(con) {
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    if(!dbExistsTable(con, "triangulaire_results")) {  # ‚úÖ MINUSCULES
      dbExecute(con, "CREATE TABLE IF NOT EXISTS triangulaire_results (
        id SERIAL PRIMARY KEY,
        source_name VARCHAR(255) NOT NULL,
        idtest VARCHAR(255),
        test_type VARCHAR(50),
        reference VARCHAR(255),
        candidate VARCHAR(255),
        n_total INTEGER,
        n_correct INTEGER,
        p_value NUMERIC,
        decision VARCHAR(50),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )")
      
      # Cr√©er les index s√©par√©ment
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_triangular_source ON triangulaire_results(source_name)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_triangular_type ON triangulaire_results(test_type)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_triangular_decision ON triangulaire_results(decision)")
      
      message("Table triangulaire_results cr√©√©e avec succ√®s")
    }
    return(TRUE)
  }, error = function(e) {
    message("Erreur cr√©ation table triangulaire_results : ", e$message)
    return(FALSE)
  })
}



# ===== FONCTION POUR D√âTERMINER LE NOM DE LA TABLE =====
get_results_table_name <- function(test_type) {
  switch(test_type,
         "Strength" = "strengthandmo_results",           # ‚úÖ MINUSCULES
         "Strength with Malodour" = "strengthandmo_results", # ‚úÖ MINUSCULES
         "Proximity" = "proximity_results",              # ‚úÖ MINUSCULES
         "Triangular" = "triangulaire_results",          # ‚úÖ MINUSCULES
         "strengthandmo_results"  # Par d√©faut en minuscules
  )
}


# ===== FONCTION POUR CR√âER LA TABLE APPROPRI√âE =====
create_appropriate_results_table <- function(con, test_type) {
  switch(test_type,
         "Strength" = create_strength_results_table(con),
         "Strength with Malodour" = create_strength_results_table(con),
         "Proximity" = create_proximity_results_table(con),
         "Triangular" = create_triangular_results_table(con),
         create_strength_results_table(con)  # Par d√©faut
  )
}



create_judges_table <- function(con) {
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    if(!dbExistsTable(con, "judge_tracking")) {
      dbExecute(con, "CREATE TABLE IF NOT EXISTS judge_tracking (
        id SERIAL PRIMARY KEY,
        cj VARCHAR(100),                          -- ‚úÖ Pas de NOT NULL
        nb_fichiers_participes INTEGER,           -- ‚úÖ NOUVEAU
        nb_evaluations_total INTEGER,             -- ‚úÖ Total au lieu de par fichier
        moyenne_score_globale NUMERIC,            -- ‚úÖ Moyenne globale
        attributes_evalues_total INTEGER,         -- ‚úÖ Total
        produits_evalues_total INTEGER,           -- ‚úÖ Total
        nb_segments_total INTEGER,                -- ‚úÖ Total global
        nb_segments_retire_total INTEGER,         -- ‚úÖ Total retraits
        nb_segments_conserve INTEGER,             -- ‚úÖ Total conserv√©s
        taux_conservation_global NUMERIC,         -- ‚úÖ Taux global
        nb_fichiers_avec_retrait INTEGER,         -- ‚úÖ NOUVEAU
        premier_fichier VARCHAR(255),             -- ‚úÖ R√©f√©rence
        dernier_fichier VARCHAR(255),             -- ‚úÖ R√©f√©rence
        date_analyse DATE,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )")
      
      # ‚úÖ INDEX OPTIMIS√âS
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_judges_cj ON judge_tracking(cj)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_judges_taux_global ON judge_tracking(taux_conservation_global)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_judges_nb_fichiers ON judge_tracking(nb_fichiers_participes)")
      
      message("Table judge_tracking OPTIMIS√âE cr√©√©e avec succ√®s")
    }
    return(TRUE)
  }, error = function(e) {
    message("Erreur cr√©ation table judge_tracking : ", e$message)
    return(FALSE)
  })
}





create_metadata_table <- function(con) {
  
  if(is.null(con)) return(FALSE)
  
  
  
  tryCatch({
    
    if(!dbExistsTable(con, "databrute")) {
      
      dbExecute(con, "CREATE TABLE IF NOT EXISTS databrute (

        id SERIAL PRIMARY KEY,

        idtest VARCHAR(255),

        productname VARCHAR(255),

        sourcefile VARCHAR(255),

        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP

      )")
      
      
      
      # Cr√©er les index s√©par√©ment
      
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_databrute_product ON databrute(productname)")
      
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_databrute_source ON databrute(sourcefile)")
      
      dbExecute(con, "CREATE UNIQUE INDEX IF NOT EXISTS idx_databrute_unique ON databrute(sourcefile, productname)")
      
      
      
      message("Table databrute cr√©√©e avec succ√®s dans SA_METADATA")
      
    }
    
    
    
    return(TRUE)
    
    
    
  }, error = function(e) {
    
    message("Erreur cr√©ation table databrute : ", e$message)
    
    return(FALSE)
    
  })
  
}


# ===== FONCTIONS DE SAUVEGARDE DANS LES BASES =====
save_raw_data_to_db <- function(raw_data, source_name) {
  con <- create_db_connection(DATABASES$RAW_DATA)
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    # Cr√©er la table si n√©cessaire
    create_raw_data_table(con)
    
    # Pr√©parer les donn√©es avec SOURCE_NAME
    raw_data_db <- raw_data %>%
      mutate(
        source_name = source_name,
        trial_name = TrialName,
        cj = CJ,
        product_name = ProductName,
        attribute_name = AttributeName,
        nom_fonction = NomFonction,
        value = as.numeric(Value),
        judge_status = "conserved"  # Valeur par d√©faut au lieu de v√©rifier JudgeStatus
      ) %>%
      select(source_name, trial_name, cj, product_name, attribute_name, 
             nom_fonction, value, judge_status)
    
    # Supprimer les donn√©es existantes pour ce fichier source
    dbExecute(con, "DELETE FROM rawdata WHERE source_name = $1", params = list(source_name))
    
    # Ins√©rer les nouvelles donn√©es
    dbWriteTable(con, "rawdata", raw_data_db, append = TRUE, row.names = FALSE)
    
    message("Donn√©es brutes sauvegard√©es pour : ", source_name, " (", nrow(raw_data_db), " lignes)")
    safe_disconnect(con)
    return(TRUE)
    
  }, error = function(e) {
    message("Erreur sauvegarde donn√©es brutes : ", e$message)
    safe_disconnect(con)
    return(FALSE)
  })
}
# ===== FONCTION DE SAUVEGARDE DES DONN√âES BRUTES AVEC STATUT JUGES =====
save_raw_data_with_judge_status <- function(raw_data, source_name, judge_removal_info_file = NULL) {
  con <- create_db_connection(DATABASES$RAW_DATA)
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    # Cr√©er la table si n√©cessaire
    create_raw_data_table(con)
    
    # Pr√©parer les donn√©es de base
    raw_data_db <- raw_data %>%
      mutate(
        source_name = source_name,
        trial_name = TrialName,
        cj = CJ,
        product_name = ProductName,
        attribute_name = AttributeName,
        nom_fonction = NomFonction,
        value = as.numeric(Value),
        judge_status = "conserved"  # Valeur par d√©faut
      )
    
    # Si on a des informations sur les juges retir√©s, les appliquer
    if(!is.null(judge_removal_info_file) && nrow(judge_removal_info_file) > 0) {
      message("Application du statut des juges retir√©s...")
      
      # Pour chaque juge retir√©, mettre √† jour le statut
      for(i in 1:nrow(judge_removal_info_file)) {
        removed_judges <- unlist(strsplit(judge_removal_info_file$RemovedJudges[i], ", "))
        segment_name <- judge_removal_info_file$Segment[i]
        
        # Extraire AttributeName et NomFonction du segment
        segment_parts <- strsplit(segment_name, " - ")[[1]]
        if(length(segment_parts) >= 2) {
          attr_name <- segment_parts[1]
          nom_fonction <- segment_parts[2]
          
          # Mettre √† jour le statut pour ces juges dans ce segment
          raw_data_db <- raw_data_db %>%
            mutate(judge_status = case_when(
              cj %in% removed_judges & 
                attribute_name == attr_name & 
                nom_fonction == nom_fonction ~ "removed",
              TRUE ~ judge_status
            ))
        }
      }
      
      nb_removed <- sum(raw_data_db$judge_status == "removed")
      message("Statut mis √† jour pour ", nb_removed, " lignes (juges retir√©s)")
    }
    
    # S√©lectionner les colonnes finales
    raw_data_db <- raw_data_db %>%
      select(source_name, trial_name, cj, product_name, attribute_name, 
             nom_fonction, value, judge_status)
    
    # Supprimer les donn√©es existantes pour ce fichier source
    dbExecute(con, "DELETE FROM rawdata WHERE source_name = $1", params = list(source_name))
    
    # Ins√©rer les nouvelles donn√©es
    dbWriteTable(con, "rawdata", raw_data_db, append = TRUE, row.names = FALSE)
    
    nb_conserved <- sum(raw_data_db$judge_status == "conserved")
    nb_removed <- sum(raw_data_db$judge_status == "removed")
    
    message("Donn√©es brutes sauvegard√©es pour : ", source_name, 
            " (", nrow(raw_data_db), " lignes total, ",
            nb_conserved, " conserv√©es, ", nb_removed, " retir√©es)")
    
    safe_disconnect(con)
    return(TRUE)
    
  }, error = function(e) {
    message("Erreur sauvegarde donn√©es brutes avec statut : ", e$message)
    safe_disconnect(con)
    return(FALSE)
  })
}


# ===== FONCTION DE SAUVEGARDE MODIFI√âE =====
save_results_to_db <- function(results_data, source_name, test_type) {
  con <- create_db_connection(DATABASES$RESULTS)
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    # Cr√©er la table appropri√©e selon le type de test
    create_appropriate_results_table(con, test_type)
    
    # D√©terminer le nom de la table
    table_name <- get_results_table_name(test_type)
    
    # Adapter les donn√©es selon le type de test
    if(test_type == "Triangular") {
      results_db <- results_data %>%
        mutate(
          source_name = source_name,
          test_type = test_type,
          idtest = IDTEST,
          reference = REFERENCE,
          candidate = CANDIDATE,
          n_total = N,
          n_correct = CORRECT,
          p_value = P_VALUE,
          decision = DECISION
        ) %>%
        select(source_name, idtest, test_type, reference, candidate, 
               n_total, n_correct, p_value, decision)
      
    } else if(test_type == "Proximity") {
      # Tests de proximit√© (sans colonnes ANOVA)
      results_db <- results_data %>%
        mutate(
          source_name = source_name,
          test_type = test_type,
          idtest = IDTEST,
          segment = SEGMENT,
          segment_id = IDSEGMENT,
          product_name = PRODUCT,
          classe = CLASSE,
          mean_value = MEAN,
          sd_value = SD,
          n_observations = N
        ) %>%
        select(source_name, idtest, test_type, segment, segment_id, product_name,
               classe, mean_value, sd_value, n_observations)
      
    } else {
      # Tests standard (Strength, Strength with Malodour) - avec colonnes ANOVA
      results_db <- results_data %>%
        mutate(
          source_name = source_name,
          test_type = test_type,
          idtest = IDTEST,
          segment = SEGMENT,
          segment_id = IDSEGMENT,
          product_name = PRODUCT,
          classe = CLASSE,
          mean_value = MEAN,
          sd_value = SD,
          n_observations = N,
          anova_5pct = ifelse("ANOVA √† 5%" %in% names(.), 
                              ifelse(`ANOVA √† 5%` == "true", TRUE, FALSE), FALSE),
          anova_10pct = ifelse("ANOVA √† 10%" %in% names(.), 
                               ifelse(`ANOVA √† 10%` == "true", TRUE, FALSE), FALSE)
        ) %>%
        select(source_name, idtest, test_type, segment, segment_id, product_name,
               classe, mean_value, sd_value, n_observations, anova_5pct, anova_10pct)
    }
    
    # Supprimer les r√©sultats existants pour ce fichier dans la table appropri√©e
    dbExecute(con, paste0("DELETE FROM ", table_name, " WHERE source_name = $1"), 
              params = list(source_name))
    
    # Ins√©rer les nouveaux r√©sultats dans la table appropri√©e
    dbWriteTable(con, table_name, results_db, append = TRUE, row.names = FALSE)
    
    message("R√©sultats sauvegard√©s (", test_type, ") dans ", table_name, " pour : ", 
            source_name, " (", nrow(results_db), " lignes)")
    safe_disconnect(con)
    return(TRUE)
    
  }, error = function(e) {
    message("Erreur sauvegarde r√©sultats dans ", table_name, " : ", e$message)
    safe_disconnect(con)
    return(FALSE)
  })
}

save_judges_to_db <- function(judge_data, source_name = "GLOBAL") {
  con <- create_db_connection(DATABASES$JUDGES)
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    create_judges_table(con)
    
    if(nrow(judge_data) == 0) {
      message("Aucune donn√©e de juge √† sauvegarder")
      safe_disconnect(con)
      return(TRUE)
    }
    
    if(!"CJ" %in% names(judge_data)) {
      message("Colonne CJ manquante dans les donn√©es de juges")
      safe_disconnect(con)
      return(FALSE)
    }
    
    # ‚úÖ PR√âPARATION DONN√âES AVEC VALIDATION RENFORC√âE
    judges_db <- judge_data %>%
      filter(!is.na(CJ) & CJ != "" & !is.null(CJ) & CJ != "NULL") %>%
      mutate(
        cj = as.character(CJ),
        nb_fichiers_participes = coalesce(nb_fichiers_participes, 1),
        nb_evaluations_total = coalesce(nb_evaluations_total, 0),
        moyenne_score_globale = coalesce(moyenne_score_globale, 0),
        attributes_evalues_total = coalesce(attributes_evalues_total, 0),
        produits_evalues_total = coalesce(produits_evalues_total, 0),
        nb_segments_total = coalesce(nb_segments_total, 0),
        nb_segments_retire_total = coalesce(nb_segments_retire_total, 0),
        nb_segments_conserve = coalesce(nb_segments_conserve, nb_segments_total),
        taux_conservation_global = coalesce(taux_conservation_global, 1.000),
        nb_fichiers_avec_retrait = coalesce(nb_fichiers_avec_retrait, 0),
        premier_fichier = coalesce(premier_fichier, ""),
        dernier_fichier = coalesce(dernier_fichier, ""),
        date_analyse = Sys.Date()
      ) %>%
      filter(!is.na(cj) & cj != "") %>%
      select(cj, nb_fichiers_participes, nb_evaluations_total, moyenne_score_globale,
             attributes_evalues_total, produits_evalues_total, nb_segments_total,
             nb_segments_retire_total, nb_segments_conserve, taux_conservation_global,
             nb_fichiers_avec_retrait, premier_fichier, dernier_fichier, date_analyse)
    
    if(nrow(judges_db) == 0) {
      message("Aucune donn√©e de juge valide apr√®s nettoyage")
      safe_disconnect(con)
      return(TRUE)
    }
    
    # ‚úÖ AFFICHAGE DE CONTR√îLE AVANT SAUVEGARDE
    message("üìä Contr√¥le avant sauvegarde :")
    message("   ‚Ä¢ Nombre de juges : ", nrow(judges_db))
    message("   ‚Ä¢ Plage √©valuations : ", min(judges_db$nb_evaluations_total), " - ", max(judges_db$nb_evaluations_total))
    message("   ‚Ä¢ Plage moyennes : ", round(min(judges_db$moyenne_score_globale, na.rm = TRUE), 2), " - ", round(max(judges_db$moyenne_score_globale, na.rm = TRUE), 2))
    
    # ‚úÖ SUPPRESSION/INSERTION GLOBALE
    dbExecute(con, "DELETE FROM judge_tracking")
    dbWriteTable(con, "judge_tracking", judges_db, append = TRUE, row.names = FALSE)
    
    message("‚úÖ Tracking juges sauvegard√© : ", nrow(judges_db), " juges uniques")
    safe_disconnect(con)
    return(TRUE)
    
  }, error = function(e) {
    message("‚ùå Erreur sauvegarde tracking juges : ", e$message)
    safe_disconnect(con)
    return(FALSE)
  })
}





# ===== CR√âATION DES 2 TABLES POUR L'APPLICATION SHINY =====

# ===== CORRECTION DES NOMS DE TABLES METADATA =====
create_product_info_table <- function(con) {
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    if(!dbExistsTable(con, "product_info")) {  # Minuscules
      dbExecute(con, "CREATE TABLE IF NOT EXISTS product_info (
        id SERIAL PRIMARY KEY,
        source_name VARCHAR(255) NOT NULL,
        product_name VARCHAR(255) NOT NULL,
        idtest VARCHAR(255),
        code_prod VARCHAR(255),
        base VARCHAR(255),
        ref VARCHAR(10),
        dosage VARCHAR(50),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )")
      
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_product_info_source ON product_info(source_name)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_product_info_product ON product_info(product_name)")
      dbExecute(con, "CREATE UNIQUE INDEX IF NOT EXISTS idx_product_info_unique ON product_info(source_name, product_name)")
      
      message("Table product_info cr√©√©e avec succ√®s dans SA_METADATA")
    }
    return(TRUE)
  }, error = function(e) {
    message("Erreur cr√©ation table product_info : ", e$message)
    return(FALSE)
  })
}

create_test_info_table <- function(con) {
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    if(!dbExistsTable(con, "test_info")) {  # Minuscules
      dbExecute(con, "CREATE TABLE IF NOT EXISTS test_info (
        id SERIAL PRIMARY KEY,
        source_name VARCHAR(255) NOT NULL,
        test_name VARCHAR(255) NOT NULL,
        gmps_type VARCHAR(10),
        gpms_code VARCHAR(100),
        sc_request VARCHAR(50),
        test_date VARCHAR(20),
        master_customer_name VARCHAR(255),
        country_client VARCHAR(100),
        type_of_test VARCHAR(50),
        category VARCHAR(100),
        subsegment VARCHAR(100),
        methodology VARCHAR(100),
        panel VARCHAR(100),
        test_facilities VARCHAR(100),
        scale VARCHAR(100),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )")
      
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_test_info_source ON test_info(source_name)")
      dbExecute(con, "CREATE INDEX IF NOT EXISTS idx_test_info_test_name ON test_info(test_name)")
      dbExecute(con, "CREATE UNIQUE INDEX IF NOT EXISTS idx_test_info_unique ON test_info(source_name, test_name)")
      
      message("Table test_info cr√©√©e avec succ√®s dans SA_METADATA")
    }
    return(TRUE)
  }, error = function(e) {
    message("Erreur cr√©ation table test_info : ", e$message)
    return(FALSE)
  })
}


# ===== FONCTIONS DE SAUVEGARDE AVEC ENREGISTREMENTS VIDES =====

# Sauvegarder Product_Info avec tous les champs (vides √† remplir par l'app)
# ===== FONCTIONS DE SAUVEGARDE CORRIG√âES =====
save_product_info_complete <- function(raw_data, source_name) {
  con <- create_db_connection(DATABASES$METADATA)
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    create_product_info_table(con)
    
    # Extraire les couples uniques (SOURCE_NAME, ProductName)
    product_info <- raw_data %>%
      select(TrialName, ProductName) %>%
      distinct() %>%
      mutate(
        source_name = source_name,
        product_name = ProductName,
        idtest = TrialName,
        code_prod = "",
        base = "",
        ref = "",
        dosage = ""
      ) %>%
      select(source_name, product_name, idtest, code_prod, base, ref, dosage)
    
    # Supprimer les entr√©es existantes pour ce source_name
    dbExecute(con, "DELETE FROM product_info WHERE source_name = $1", params = list(source_name))
    
    # Ins√©rer les nouvelles donn√©es
    dbWriteTable(con, "product_info", product_info, append = TRUE, row.names = FALSE)
    
    message("Product_Info complet sauvegard√© : ", source_name, " (", nrow(product_info), " produits)")
    safe_disconnect(con)
    return(TRUE)
    
  }, error = function(e) {
    message("Erreur sauvegarde product_info : ", e$message)
    safe_disconnect(con)
    return(FALSE)
  })
}

save_test_info_complete <- function(raw_data, source_name) {
  con <- create_db_connection(DATABASES$METADATA)
  if(is.null(con)) return(FALSE)
  
  tryCatch({
    create_test_info_table(con)
    
    # Extraire les test_names uniques
    test_info <- raw_data %>%
      select(TrialName) %>%
      distinct() %>%
      mutate(
        source_name = source_name,
        test_name = TrialName,
        gmps_type = "",
        gpms_code = "",
        sc_request = "",
        test_date = "",
        master_customer_name = "",
        country_client = "",
        type_of_test = "",
        category = "",
        subsegment = "",
        methodology = "",
        panel = "",
        test_facilities = "",
        scale=""
      ) %>%
      select(-TrialName)
    
    # V√©rifier si l'enregistrement existe d√©j√†
    for(i in 1:nrow(test_info)) {
      test_record <- test_info[i, ]
      
      existing <- dbGetQuery(con, 
                             "SELECT COUNT(*) as count FROM test_info WHERE source_name = $1 AND test_name = $2",
                             params = list(test_record$source_name, test_record$test_name))
      
      if(existing$count == 0) {
        # Ins√©rer l'enregistrement vide
        dbWriteTable(con, "test_info", test_record, append = TRUE, row.names = FALSE)
      }
    }
    
    message("Test_Info complet sauvegard√© : ", source_name, " (", nrow(test_info), " tests)")
    safe_disconnect(con)
    return(TRUE)
    
  }, error = function(e) {
    message("Erreur sauvegarde test_info : ", e$message)
    safe_disconnect(con)
    return(FALSE)
  })
}




# ===== INITIALISATION =====
# ===== INITIALISATION =====
message("D√©but analyse avec int√©gration multi-databases: ", Sys.time())

# ‚úÖ DOSSIERS SP√âCIFIQUES √Ä TRAITER
target_dirs <- c(
  "//emea/dfs/Fizzdata/CRP/Fizz_Manon",
  "//emea/dfs/Fizzdata/CRP/Fizz_Cecile",
  "//emea/dfs/Fizzdata/CRP/Fizz_Alizee"
)

output_base_dir <- "C:/ResultatsAnalyseSenso"

if(!dir.exists(output_base_dir)) {
  dir.create(output_base_dir, recursive = TRUE, showWarnings = FALSE)
  message("Cr√©ation du dossier de sortie principal: ", output_base_dir)
}

# ‚úÖ V√âRIFICATION DE L'EXISTENCE DES DOSSIERS CIBLES
existing_dirs <- target_dirs[dir.exists(target_dirs)]
missing_dirs <- target_dirs[!dir.exists(target_dirs)]

if(length(missing_dirs) > 0) {
  message("‚ö†Ô∏è Dossiers manquants :")
  for(dir in missing_dirs) {
    message("   - ", dir)
  }
}

if(length(existing_dirs) == 0) {
  stop("‚ùå ERREUR : Aucun des dossiers cibles n'existe !")
}

message("‚úÖ Dossiers cibles trouv√©s :")
for(dir in existing_dirs) {
  message("   - ", dir)
}


# ===== SYST√àME DE TRACKING =====
tracking_file <- file.path(output_base_dir, "TRACKING_FICHIERS.xlsx")

load_tracking_data <- function() {
  if(file.exists(tracking_file)) {
    tryCatch({
      tracking_data <- read_excel(tracking_file)
      message("Fichier de tracking charg√©: ", nrow(tracking_data), " entr√©es")
      return(tracking_data)
    }, error = function(e) {
      message("Erreur lecture tracking, cr√©ation nouveau fichier: ", e$message)
      return(tibble(
        Fichier = character(0),
        Chemin_Complet = character(0),
        Hash_MD5 = character(0),
        Date_Traitement = as.POSIXct(character(0)),
        Statut = character(0),
        Taille_Fichier = numeric(0),
        Nb_Lignes_Results = numeric(0)
      ))
    })
  } else {
    message("Cr√©ation nouveau fichier de tracking")
    return(tibble(
      Fichier = character(0),
      Chemin_Complet = character(0),
      Hash_MD5 = character(0),
      Date_Traitement = as.POSIXct(character(0)),
      Statut = character(0),
      Taille_Fichier = numeric(0),
      Nb_Lignes_Results = numeric(0)
    ))
  }
}

calculate_file_hash <- function(file_path) {
  tryCatch({
    digest(file_path, algo = "md5", file = TRUE)
  }, error = function(e) {
    message("Erreur calcul hash pour ", basename(file_path), ": ", e$message)
    return(NA_character_)
  })
}

is_file_already_processed <- function(file_path, tracking_data) {
  if(nrow(tracking_data) == 0) return(FALSE)
  
  current_hash <- calculate_file_hash(file_path)
  if(is.na(current_hash)) return(FALSE)
  
  existing_entry <- tracking_data %>%
    filter(
      Fichier == basename(file_path) &
        Hash_MD5 == current_hash &
        Statut == "SUCCES"
    )
  
  return(nrow(existing_entry) > 0)
}

update_tracking <- function(file_path, statut, nb_lignes = NA, tracking_data) {
  current_hash <- calculate_file_hash(file_path)
  file_size <- file.info(file_path)$size
  
  new_entry <- tibble(
    Fichier = basename(file_path),
    Chemin_Complet = as.character(file_path),
    Hash_MD5 = current_hash,
    Date_Traitement = Sys.time(),
    Statut = statut,
    Taille_Fichier = file_size,
    Nb_Lignes_Results = nb_lignes
  )
  
  tracking_data_updated <- tracking_data %>%
    filter(!(
      Fichier == basename(file_path) & 
        Hash_MD5 == current_hash
    ))
  
  tracking_data_updated <- bind_rows(tracking_data_updated, new_entry)
  return(tracking_data_updated)
}

save_tracking_data <- function(tracking_data) {
  tryCatch({
    write_xlsx(tracking_data, tracking_file)
    message("Fichier de tracking sauvegard√©: ", tracking_file)
  }, error = function(e) {
    message("Erreur sauvegarde tracking: ", e$message)
  })
}

# ===== FONCTIONS UTILITAIRES ET D'ANALYSE =====

# Fonction de logging centralis√© pour les probl√®mes de donn√©es
log_probleme <- function(type, details, fichier) {
  msg <- paste0(
    "[", type, "] ",
    details,
    " | Fichier: ", basename(fichier)
  )
  
  data_issues_log <<- append(data_issues_log, msg)
  message("PROBLEME: ", msg)
}

# Fonction de validation de la coh√©rence des donn√©es
validate_data_consistency <- function(file_data) {
  issues <- character()
  
  invalid_values <- sum(
    is.na(as.numeric(file_data$Value)) &
      !is.na(file_data$Value)
  )
  
  if(invalid_values > 0) {
    issues <- c(issues, paste("Valeurs non num√©riques d√©tect√©es:", invalid_values))
  }
  
  return(issues)
}

create_judge_tracking_table <- function(all_judge_info, all_raw_data) {
  tryCatch({
    if(nrow(all_raw_data) == 0) {
      message("Aucune donn√©e brute disponible pour le tracking des juges")
      return(tibble(Message = "Aucune donn√©e disponible", Timestamp = Sys.time()))
    }
    
    # ‚úÖ CORRECTION : Filtrer les valeurs CJ NULL/vides d√®s le d√©but
    all_raw_data_clean <- all_raw_data %>%
      filter(!is.na(CJ) & CJ != "" & !is.null(CJ) & CJ != "NULL") %>%
      filter(!is.na(Value) & is.numeric(Value))  # ‚úÖ AJOUT : Filtrer les valeurs non-num√©riques
    
    if(nrow(all_raw_data_clean) == 0) {
      message("Aucune donn√©e avec CJ valide pour le tracking des juges")
      return(tibble(Message = "Aucun juge valide trouv√©", Timestamp = Sys.time()))
    }
    
    message("‚úÖ Donn√©es nettoy√©es : ", nrow(all_raw_data_clean), " lignes valides pour ", 
            n_distinct(all_raw_data_clean$CJ), " juges uniques")
    
    # ‚úÖ CORRECTION : AGR√âGATION GLOBALE PAR JUGE (calculs corrects)
    judge_participation <- all_raw_data_clean %>%
      group_by(CJ) %>%
      summarise(
        nb_fichiers_participes = n_distinct(SourceFile, na.rm = TRUE),
        nb_evaluations_total = n(),  # ‚úÖ Total r√©el par juge
        moyenne_score_globale = round(mean(Value, na.rm = TRUE), 3),  # ‚úÖ Moyenne r√©elle par juge
        attributes_evalues_total = n_distinct(AttributeName, na.rm = TRUE),
        produits_evalues_total = n_distinct(ProductName, na.rm = TRUE),
        premier_fichier = min(SourceFile, na.rm = TRUE),
        dernier_fichier = max(SourceFile, na.rm = TRUE),
        .groups = 'drop'
      ) %>%
      filter(!is.na(CJ) & CJ != "") %>%
      mutate(date_analyse = Sys.Date())
    
    # ‚úÖ CORRECTION : CALCUL CORRECT DES SEGMENTS PAR JUGE
    segments_per_judge <- all_raw_data_clean %>%
      group_by(CJ) %>%
      summarise(
        nb_segments_total = n_distinct(paste(SourceFile, AttributeName, NomFonction, sep = "_SEPARATOR_"), na.rm = TRUE),
        .groups = 'drop'
      ) %>%
      filter(!is.na(CJ) & CJ != "")
    
    # ‚úÖ CORRECTION : CALCUL CORRECT DES RETRAITS
    if(nrow(all_judge_info) > 0 && "RemovedJudges" %in% names(all_judge_info)) {
      # Traitement plus robuste des juges retir√©s
      judge_removal_global <- all_judge_info %>%
        filter(!is.na(RemovedJudges) & RemovedJudges != "") %>%
        separate_rows(RemovedJudges, sep = ", ") %>%
        filter(RemovedJudges != "" & !is.na(RemovedJudges)) %>%
        rename(CJ = RemovedJudges) %>%
        filter(!is.na(CJ) & CJ != "") %>%
        group_by(CJ) %>%
        summarise(
          nb_segments_retire_total = n(),
          nb_fichiers_avec_retrait = n_distinct(File, na.rm = TRUE),
          .groups = 'drop'
        )
      
      # ‚úÖ JOINTURE ET CALCULS CORRECTS
      segments_conservation <- segments_per_judge %>%
        left_join(judge_removal_global, by = "CJ") %>%
        mutate(
          nb_segments_retire_total = coalesce(nb_segments_retire_total, 0),
          nb_segments_conserve = pmax(0, nb_segments_total - nb_segments_retire_total),  # ‚úÖ √âviter les valeurs n√©gatives
          taux_conservation_global = round(
            ifelse(nb_segments_total > 0, nb_segments_conserve / nb_segments_total, 1), 
            3
          ),
          nb_fichiers_avec_retrait = coalesce(nb_fichiers_avec_retrait, 0)
        )
    } else {
      segments_conservation <- segments_per_judge %>%
        mutate(
          nb_segments_retire_total = 0,
          nb_segments_conserve = nb_segments_total,
          taux_conservation_global = 1.000,
          nb_fichiers_avec_retrait = 0
        )
    }
    
    # ‚úÖ JOINTURE FINALE AVEC V√âRIFICATIONS
    judge_tracking <- judge_participation %>%
      left_join(segments_conservation, by = "CJ") %>%
      filter(!is.na(CJ) & CJ != "") %>%
      mutate(
        # ‚úÖ V√©rifications de coh√©rence
        nb_segments_total = coalesce(nb_segments_total, 0),
        nb_segments_retire_total = coalesce(nb_segments_retire_total, 0),
        nb_segments_conserve = coalesce(nb_segments_conserve, nb_segments_total),
        taux_conservation_global = coalesce(taux_conservation_global, 1.000),
        nb_fichiers_avec_retrait = coalesce(nb_fichiers_avec_retrait, 0)
      )
    
    if(nrow(judge_tracking) == 0) {
      message("Aucune donn√©e de tracking valide apr√®s nettoyage")
      return(tibble(Message = "Aucune donn√©e de tracking valide", Timestamp = Sys.time()))
    }
    
    # ‚úÖ AFFICHAGE DE STATISTIQUES DE CONTR√îLE
    message("‚úÖ Table de tracking cr√©√©e avec ", nrow(judge_tracking), " juges uniques")
    message("   ‚Ä¢ Moyenne des √©valuations par juge : ", round(mean(judge_tracking$nb_evaluations_total), 1))
    message("   ‚Ä¢ Moyenne des scores : ", round(mean(judge_tracking$moyenne_score_globale, na.rm = TRUE), 2))
    message("   ‚Ä¢ Taux de conservation moyen : ", round(mean(judge_tracking$taux_conservation_global, na.rm = TRUE), 3))
    
    return(judge_tracking)
    
  }, error = function(e) {
    message("‚ùå Erreur cr√©ation table tracking juges: ", e$message)
    return(tibble(Erreur = paste("√âchec cr√©ation table tracking:", e$message), Timestamp = Sys.time()))
  })
}





# ===== FONCTION GESTION DES TESTS DE PROXIMIT√â =====
handle_proximity_test <- function(segment) {
  tryCatch({
    # V√©rification initiale des donn√©es
    if(is.null(segment) || nrow(segment) == 0) {
      message("Segment vide pour test proximit√©")
      return(list(
        segment = segment,
        removed_judges = character(0),
        n_initial = 0,
        n_final = 0
      ))
    }
    
    # Validation des colonnes n√©cessaires
    if(!"ProductName" %in% names(segment) || !"Value" %in% names(segment) || !"CJ" %in% names(segment)) {
      message("Colonnes manquantes pour test proximit√©")
      return(list(
        segment = segment,
        removed_judges = character(0),
        n_initial = n_distinct(segment$CJ),
        n_final = n_distinct(segment$CJ)
      ))
    }
    
    # Nettoyer les donn√©es
    segment <- segment %>%
      filter(!is.na(ProductName) & !is.na(Value) & !is.na(CJ) & 
               ProductName != "" & CJ != "")
    
    if(nrow(segment) == 0) {
      message("Aucune donn√©e valide apr√®s nettoyage pour test proximit√©")
      return(list(
        segment = segment,
        removed_judges = character(0),
        n_initial = 0,
        n_final = 0
      ))
    }
    
    n_judges_initial <- n_distinct(segment$CJ)
    
    # Identifier le produit de r√©f√©rence (celui avec la moyenne la plus faible)
    bench_product <- segment %>%
      group_by(ProductName) %>%
      summarise(avg = mean(Value, na.rm = TRUE), .groups = 'drop') %>%
      filter(!is.na(avg)) %>%
      slice_min(avg, n = 1, with_ties = FALSE) %>%
      pull(ProductName)
    
    if(length(bench_product) == 0) {
      message("Impossible de d√©terminer le produit de r√©f√©rence")
      return(list(
        segment = segment,
        removed_judges = character(0),
        n_initial = n_judges_initial,
        n_final = n_judges_initial
      ))
    }
    
    message("Produit de r√©f√©rence identifi√©: ", bench_product)
    
    # Identifier les juges √† filtrer avec gestion d'erreur robuste
    filtered_judges <- segment %>%
      group_by(CJ) %>%
      summarise(
        # V√©rifier si le juge a √©valu√© le produit de r√©f√©rence
        has_bench_score = any(ProductName %in% bench_product),
        # Calculer le score du produit de r√©f√©rence (avec valeur par d√©faut)
        bench_score = ifelse(
          any(ProductName %in% bench_product),
          Value[ProductName %in% bench_product][1],  # Prendre la premi√®re valeur si plusieurs
          NA
        ),
        # V√©rifier les conditions de filtrage
        bench_too_high = ifelse(
          !is.na(bench_score),
          bench_score > 4,
          FALSE
        ),
        # V√©rifier si d'autres produits ont des scores <= bench_score - 1
        other_products_low = ifelse(
          !is.na(bench_score) & any(!ProductName %in% bench_product),
          any(Value[!ProductName %in% bench_product] <= (bench_score - 1), na.rm = TRUE),
          FALSE
        ),
        .groups = 'drop'
      ) %>%
      # Filtrer les juges selon les crit√®res
      filter(
        !has_bench_score |  # Juge n'a pas √©valu√© le produit de r√©f√©rence
          bench_too_high |    # Score de r√©f√©rence > 4
          other_products_low  # Autres produits avec score <= bench_score - 1
      ) %>%
      pull(CJ)
    
    # Appliquer le filtrage
    filtered_segment <- segment %>%
      filter(!CJ %in% filtered_judges)
    
    n_judges_final <- n_distinct(filtered_segment$CJ)
    
    message("Juges filtr√©s pour proximit√©: ", length(filtered_judges), 
            " | Juges restants: ", n_judges_final)
    
    if(length(filtered_judges) > 0) {
      message("Juges retir√©s: ", paste(filtered_judges, collapse = ", "))
    }
    
    return(list(
      segment = filtered_segment,
      removed_judges = filtered_judges,
      n_initial = n_judges_initial,
      n_final = n_judges_final
    ))
    
  }, error = function(e) {
    message("Erreur dans handle_proximity_test: ", e$message)
    return(list(
      segment = segment,
      removed_judges = character(0),
      n_initial = n_distinct(segment$CJ),
      n_final = n_distinct(segment$CJ)
    ))
  })
}


# ===== FONCTION CORRIG√âE POUR LES SEGMENTS TRIANGULAIRES =====
process_triangular_segments <- function(segments, file_path, file_test_type) {
  # V√©rification robuste avec gestion des erreurs
  triangular_indices <- c()
  
  for(i in seq_along(segments)) {
    seg <- segments[[i]]
    
    # V√©rifications de s√©curit√©
    if(is.null(seg) || length(seg) == 0 || nrow(seg) == 0) {
      next
    }
    
    if(!"NomFonction" %in% names(seg)) {
      next
    }
    
    nom_fonction <- seg$NomFonction[1]
    if(is.na(nom_fonction) || is.null(nom_fonction)) {
      next
    }
    
    # Test de d√©tection triangulaire
    if(str_detect(nom_fonction, "Triangulaire|triangle")) {
      triangular_indices <- c(triangular_indices, i)
    }
  }
  
  if(length(triangular_indices) == 0) {
    return(NULL)
  }
  
  all_triangular_data <- bind_rows(segments[triangular_indices])
  message("Fusion de ", length(triangular_indices), " segments triangulaires en un seul")
  
  # Calcul du test triangulaire
  n_total <- sum(!is.na(all_triangular_data$Value))
  n_correct <- sum(all_triangular_data$Value == 1, na.rm = TRUE)
  
  # Test binomial
  test_result <- binom.test(n_correct, n_total, p = 1/3, alternative = "greater")
  p_value <- test_result$p.value
  decision <- ifelse(p_value < 0.05, "Significant", "Not Significant")
  
  # D√©terminer r√©f√©rence et candidat
  available_products <- unique(all_triangular_data$ProductName)
  ref_product <- ifelse(length(available_products) > 0, available_products[1], "Unknown")
  candidat_product <- ifelse(length(available_products) > 1, available_products[2], "Unknown")
  
  result <- tibble(
    IDTEST = tools::file_path_sans_ext(basename(file_path)),
    REFERENCE = ref_product,
    CANDIDATE = candidat_product,
    N = n_total,
    CORRECT = n_correct,
    P_VALUE = round(p_value, 4),
    DECISION = decision,
    TESTTYPE = file_test_type
  )
  
  return(result)
}




# ===== FONCTION D'ANALYSE IT√âRATIVE DES JUGES (SUITE) =====
analyze_judges_iterative <- function(segment) {
  # V√©rification initiale des donn√©es
  if (is.null(segment) || nrow(segment) == 0) {
    message("Segment vide ou NULL - Arr√™t du traitement")
    return(list(
      segment = segment,
      removed_judges = character(0),
      n_initial = 0,
      n_final = 0
    ))
  }
  
  # Traitement sp√©cial pour les tests MO (odeur corporelle)
  if (length(segment$AttributeName) > 0 && !is.na(segment$AttributeName[1]) && 
      str_detect(str_to_lower(segment$AttributeName[1]), "odeur corporell")) {
    
    message("Traitement MO d√©tect√© - Pas de filtrage des juges")
    
    return(list(
      segment = segment,
      removed_judges = character(0),
      n_initial = n_distinct(segment$CJ),
      n_final = n_distinct(segment$CJ)
    ))
  }
  
  # Validation des donn√©es d'entr√©e
  if (!"CJ" %in% names(segment) || !"Value" %in% names(segment)) {
    message("Colonnes CJ ou Value manquantes - Arr√™t du traitement")
    return(list(
      segment = segment,
      removed_judges = character(0),
      n_initial = n_distinct(segment$CJ),
      n_final = n_distinct(segment$CJ)
    ))
  }
  
  # Nettoyage des donn√©es CJ (√©liminer les valeurs vides/NULL)
  segment <- segment %>%
    filter(!is.na(CJ) & CJ != "" & !is.na(Value))
  
  if (nrow(segment) == 0) {
    message("Aucune donn√©e valide apr√®s nettoyage - Arr√™t du traitement")
    return(list(
      segment = segment,
      removed_judges = character(0),
      n_initial = 0,
      n_final = 0
    ))
  }
  
  n_judges_initial <- n_distinct(segment$CJ)
  removed_judges_total <- c()
  current_data <- segment
  
  # Protection contre les boucles infinies
  max_iterations <- 20
  iteration_count <- 0
  
  repeat {
    iteration_count <- iteration_count + 1
    
    # Protection contre les boucles infinies
    if (iteration_count > max_iterations) {
      message("Limite maximale d'it√©rations atteinte (", max_iterations, ") - Arr√™t forc√© du filtrage")
      break
    }
    
    n_judges_current <- n_distinct(current_data$CJ)
    
    # V√©rification du seuil minimal de juges
    if (n_judges_current <= 8) {
      message("Seuil minimal atteint (8 juges) - Arr√™t du filtrage")
      break
    }
    
    # Calcul de l'ANOVA avec gestion d'erreur
    model <- tryCatch({
      aov(Value ~ CJ, data = current_data)
    }, error = function(e) {
      message("Erreur lors du calcul ANOVA: ", e$message)
      return(NULL)
    })
    
    if (is.null(model)) {
      message("Impossible de calculer l'ANOVA - Arr√™t du filtrage")
      break
    }
    
    anova_res <- tryCatch({
      anova(model)
    }, error = function(e) {
      message("Erreur lors de l'extraction des r√©sultats ANOVA: ", e$message)
      return(NULL)
    })
    
    if (is.null(anova_res)) {
      message("Impossible d'extraire les r√©sultats ANOVA - Arr√™t du filtrage")
      break
    }
    
    p_value <- anova_res["CJ", "Pr(>F)"]
    
    if (is.na(p_value) || is.null(p_value)) {
      message("Probl√®me de calcul ANOVA (p-value NA/NULL) - Arr√™t de l'it√©ration pour ce segment.")
      break
    }
    
    # Test de significativit√©
    if (p_value >= 0.05) {
      message("Effet juge non significatif (p=", round(p_value, 4), ") - Arr√™t du filtrage")
      break
    }
    
    # V√©rification du seuil de conservation (2/3 des juges initiaux)
    if (n_judges_current <= (2/3) * n_judges_initial) {
      message("Seuil de conservation atteint (2/3 des juges initiaux) - Arr√™t du filtrage")
      break
    }
    
    # Calcul des statistiques des juges
    judge_stats <- current_data %>%
      group_by(CJ) %>%
      summarise(MeanScore = mean(Value, na.rm = TRUE), .groups = 'drop') %>%
      filter(!is.na(MeanScore)) %>%  # √âliminer les moyennes NA
      mutate(
        OverallMean = mean(MeanScore, na.rm = TRUE),
        AbsDeviation = abs(MeanScore - OverallMean)
      ) %>%
      filter(!is.na(AbsDeviation))  # √âliminer les d√©viations NA
    
    if (nrow(judge_stats) == 0) {
      message("Aucune statistique de juge calculable - Arr√™t du filtrage")
      break
    }
    
    # S√©lection du juge √† retirer (celui avec la plus grande d√©viation)
    judge_to_remove <- judge_stats %>%
      slice_max(AbsDeviation, n = 1, with_ties = FALSE) %>%
      pull(CJ)
    
    # V√©rification que le juge √† retirer n'est pas vide
    if (length(judge_to_remove) == 0 || is.na(judge_to_remove) || judge_to_remove == "") {
      message("Impossible de d√©terminer le juge √† retirer - Arr√™t du filtrage")
      break
    }
    
    # Protection contre la suppression r√©p√©t√©e du m√™me juge
    if (judge_to_remove %in% removed_judges_total) {
      message("Juge d√©j√† retir√© pr√©c√©demment (", judge_to_remove, ") - Arr√™t pour √©viter une boucle infinie")
      break
    }
    
    # V√©rification que le juge existe encore dans les donn√©es
    if (!judge_to_remove %in% current_data$CJ) {
      message("Juge √† retirer non trouv√© dans les donn√©es actuelles - Arr√™t du filtrage")
      break
    }
    
    # Ajout √† la liste des juges retir√©s
    removed_judges_total <- c(removed_judges_total, judge_to_remove)
    
    # Suppression du juge des donn√©es
    current_data <- current_data %>% 
      filter(CJ != judge_to_remove)
    
    # V√©rification que des donn√©es restent apr√®s suppression
    if (nrow(current_data) == 0) {
      message("Plus de donn√©es apr√®s suppression du juge - Arr√™t du filtrage")
      # Restaurer les donn√©es pr√©c√©dentes
      current_data <- segment %>% 
        filter(!CJ %in% removed_judges_total[-length(removed_judges_total)])
      removed_judges_total <- removed_judges_total[-length(removed_judges_total)]
      break
    }
    
    message("Juge retir√©: ", judge_to_remove,
            " | D√©viation: ", round(max(judge_stats$AbsDeviation, na.rm = TRUE), 2),
            " | Nouveau n juges: ", n_judges_current - 1,
            " | It√©ration: ", iteration_count)
  }
  
  # Validation finale
  final_n_judges <- n_distinct(current_data$CJ)
  
  return(list(
    segment = current_data,
    removed_judges = unique(removed_judges_total),
    n_initial = n_judges_initial,
    n_final = final_n_judges
  ))
}


# ===== FONCTION D'ANALYSE DES PRODUITS (MODIFI√âE POUR NOUVEAUX FORMATS) =====
analyze_products <- function(segment, segment_index, file_path = NULL, file_test_type) {
  tryCatch({
    seg_data <- segment
    
    # Traitement sp√©cial pour les tests triangulaires
    if(file_test_type == "Triangular") {
      message("D√©tection test triangulaire pour segment: ", segment$NomFonction[1])
      
      # Calcul des param√®tres du test triangulaire
      n_total <- sum(!is.na(segment$Value))
      n_correct <- sum(segment$Value == 1, na.rm = TRUE)
      
      # Test binomial avec p = 1/3
      test_result <- binom.test(n_correct, n_total, p = 1/3, alternative = "greater")
      p_value <- test_result$p.value
      
      # D√©cision bas√©e sur p-value < 0.05
      decision <- ifelse(p_value < 0.05, "Significant", "Not Significant")
      
      # D√©terminer r√©f√©rence et candidat
      available_products <- unique(segment$ProductName)
      ref_product <- ifelse(length(available_products) > 0, available_products[1], "Unknown")
      candidat_product <- ifelse(length(available_products) > 1, available_products[2], "Unknown")
      
      result <- tibble(
        IDTEST = tools::file_path_sans_ext(basename(file_path)),
        REFERENCE = ref_product,
        CANDIDATE = candidat_product,
        N = n_total,
        CORRECT = n_correct,
        P_VALUE = round(p_value, 4),
        DECISION = decision,
        TESTTYPE = file_test_type
      )
      
      return(result)
    }
    
    # Pour tous les autres types de tests (Strength, Strength with Malodour, Proximity)
    if (n_distinct(seg_data$ProductName) < 2) {
      message("Analyse impossible : moins de 2 produits dans le segment")
      return(NULL)
    }
    
    # Calcul des statistiques par produit
    stats_df <- seg_data %>%
      group_by(ProductName) %>%
      summarise(
        Mean = ifelse(n() == 0, NA, round(mean(Value, na.rm = TRUE), 2)),
        Sd = ifelse(n() < 2, NA, round(sd(Value, na.rm = TRUE), 2)),
        n = n(),
        .groups = 'drop'
      )
    
    if (any(stats_df$n == 0)) {
      warning("Groupe produit vide d√©tect√©: ", segment$AttributeName[1])
    }
    
    # ANOVA pour tester l'effet produit
    model <- aov(Value ~ ProductName, data = seg_data)
    anova_result <- anova(model)
    p_value_produit <- anova_result["ProductName", "Pr(>F)"]
    
    # Tests de significativit√© √† 5% et 10%
    anova_5pct <- ifelse(!is.na(p_value_produit) && p_value_produit < 0.05, "true", "false")
    anova_10pct <- ifelse(!is.na(p_value_produit) && p_value_produit < 0.10, "true", "false")
    
    # Test post-hoc pour les groupes (uniquement si significatif √† 10%)
    if(anova_10pct) {
      snk_result <- tryCatch({
        SNK.test(model, "ProductName", group = TRUE, alpha = 0.10)
      }, error = function(e) {
        message("SNK √©chou√©, utilisation de Duncan avec alpha=0.10")
        duncan.test(model, "ProductName", group = TRUE, alpha = 0.10)
      })
      
      result_df <- snk_result$groups %>%
        as.data.frame() %>%
        rownames_to_column("ProductName") %>%
        rename(Classe = groups) %>%
        select(ProductName, Classe) %>%
        left_join(stats_df, by = "ProductName")
    } else {
      # Si pas significatif, tous les produits dans le m√™me groupe
      result_df <- stats_df %>%
        mutate(
          ProductName = ProductName,
          Classe = "a"  # Tous dans le m√™me groupe
        )
    }
    
    # Cr√©er l'output selon le type de test
    if(file_test_type %in% c("Strength", "Strength with Malodour")) {
      # STRENGTH et STRENGTH WITH MALODOUR : IDTEST, SEGMENT, IDSEGMENT, PRODUCT, CLASSE, MEAN, SD, N, TESTTYPE, ANOVA √† 5%, ANOVA √† 10%
      result_df <- result_df %>%
        mutate(
          IDTEST = tools::file_path_sans_ext(basename(file_path)),
          SEGMENT = paste(segment$AttributeName[1], segment$NomFonction[1], sep = " - "),
          IDSEGMENT = segment_index,
          PRODUCT = ProductName,
          CLASSE = Classe,
          MEAN = Mean,
          SD = Sd,
          N = n,
          TESTTYPE = file_test_type,
          `ANOVA √† 5%` = anova_5pct,
          `ANOVA √† 10%` = anova_10pct
        ) %>%
        select(IDTEST, SEGMENT, IDSEGMENT, PRODUCT, CLASSE, MEAN, SD, N, TESTTYPE, `ANOVA √† 5%`, `ANOVA √† 10%`)
      
    } else if(file_test_type == "Proximity") {
      # PROXIMITY : IDTEST, SEGMENT, IDSEGMENT, PRODUCT, CLASSE, MEAN, SD, N, TESTTYPE
      result_df <- result_df %>%
        mutate(
          IDTEST = tools::file_path_sans_ext(basename(file_path)),
          SEGMENT = paste(segment$AttributeName[1], segment$NomFonction[1], sep = " - "),
          IDSEGMENT = segment_index,
          PRODUCT = ProductName,
          CLASSE = Classe,
          MEAN = Mean,
          SD = Sd,
          N = n,
          TESTTYPE = file_test_type
        ) %>%
        select(IDTEST, SEGMENT, IDSEGMENT, PRODUCT, CLASSE, MEAN, SD, N, TESTTYPE)
    }
    
    return(result_df)
    
  }, error = function(e) {
    warning("Erreur analyse produits: ", e$message,
            " dans ", segment$AttributeName[1], " - ", segment$NomFonction[1])
    return(NULL)
  })
}

# ===== FONCTION DE V√âRIFICATION DES SEGMENTS =====
verify_segments <- function(segment) {
  nom_fonction <- na.omit(segment$NomFonction)
  is_triangulaire <- length(nom_fonction) > 0 && 
    any(str_detect(nom_fonction, "Triangulaire|triangle"))
  
  if (is_triangulaire) {
    return(list(
      Products = NA_integer_,
      Judges = n_distinct(segment$CJ),
      MissingValues = sum(is.na(segment$Value)),
      MinJudgesOK = TRUE,
      MinProductsOK = TRUE,
      OutOfRange = sum(segment$Value < 0 | segment$Value > 1, na.rm = TRUE)
    ))
  }
  
  n_products <- n_distinct(segment$ProductName)
  n_judges <- n_distinct(segment$CJ)
  non_numeric <- suppressWarnings(
    sum(is.na(as.numeric(segment$Value)) & !is.na(segment$Value))
  )
  
  list(
    Products = n_products,
    Judges = n_judges,
    MissingValues = sum(is.na(segment$Value)),
    NonNumericValues = non_numeric,
    ValuesOver10 = sum(segment$Value > 10, na.rm = TRUE),
    NegativeValues = sum(segment$Value < 0, na.rm = TRUE),
    OutOfRange = sum(segment$Value < 0 | segment$Value > 10, na.rm = TRUE),
    MinJudgesOK = n_judges >= 3,
    MinProductsOK = n_products >= 2
  )
}

# ===== PROGRAMME PRINCIPAL MODIFI√â =====
tracking_data <- load_tracking_data()

# ‚úÖ COLLECTER LES FICHIERS EXCEL DEPUIS LES DOSSIERS SP√âCIFIQUES
excel_files <- c()
for(target_dir in existing_dirs) {
  message("üîç Scan du dossier : ", target_dir)
  
  files_in_dir <- tryCatch({
    dir_ls(target_dir, regexp = "\\.xlsx$", ignore.case = TRUE, recurse = TRUE) %>%
      as.character()
  }, error = function(e) {
    message("‚ö†Ô∏è Erreur scan ", target_dir, " : ", e$message)
    return(character(0))
  })
  
  if(length(files_in_dir) > 0) {
    excel_files <- c(excel_files, files_in_dir)
    message("   ‚Üí ", length(files_in_dir), " fichiers Excel trouv√©s")
  } else {
    message("   ‚Üí Aucun fichier Excel trouv√©")
  }
}

message("üìä TOTAL fichiers Excel d√©tect√©s: ", length(excel_files))
message("   ‚Ä¢ Fizz_Manon : ", sum(str_detect(excel_files, "Fizz_Manon")))
message("   ‚Ä¢ Fizz_Cecile : ", sum(str_detect(excel_files, "Fizz_Cecile")))


all_results <- list()
judge_removal_info <- list()
all_raw_data <- list()
data_issues_log <- list()

files_processed <- 0
files_skipped <- 0
files_new <- 0
# ===== FONCTION DE D√âTERMINATION DU TYPE DE TEST (CORRIG√âE) =====
determine_test_type <- function(segments) {
  # V√©rifier s'il y a des tests triangulaires
  triangular_count <- 0
  for(seg in segments) {
    if(!is.null(seg) && nrow(seg) > 0 && "NomFonction" %in% names(seg)) {
      nom_fonction <- seg$NomFonction[1]
      if(!is.na(nom_fonction) && str_detect(nom_fonction, "Triangulaire|triangle")) {
        triangular_count <- triangular_count + 1
      }
    }
  }
  
  if(triangular_count > 0) {
    return("Triangular")
  }
  
  # V√©rifier s'il y a des tests de proximit√© (am√©lioration de la d√©tection)
  proximity_count <- 0
  for(seg in segments) {
    if(!is.null(seg) && nrow(seg) > 0) {
      # V√©rifier dans AttributeName
      if("AttributeName" %in% names(seg)) {
        attr_name <- seg$AttributeName[1]
        if(!is.na(attr_name) && str_detect(str_to_lower(attr_name), "prox")) {
          proximity_count <- proximity_count + 1
        }
      }
      
      # V√©rifier aussi dans NomFonction
      if("NomFonction" %in% names(seg)) {
        nom_fonction <- seg$NomFonction[1]
        if(!is.na(nom_fonction) && str_detect(str_to_lower(nom_fonction), "prox")) {
          proximity_count <- proximity_count + 1
        }
      }
    }
  }
  
  if(proximity_count > 0) {
    return("Proximity")
  }
  
  # V√©rifier s'il y a des tests MO (odeur corporelle)
  mo_count <- 0
  for(seg in segments) {
    if(!is.null(seg) && nrow(seg) > 0 && "AttributeName" %in% names(seg)) {
      attr_name <- seg$AttributeName[1]
      if(!is.na(attr_name) && str_detect(str_to_lower(attr_name), "odeur corporell")) {
        mo_count <- mo_count + 1
      }
    }
  }
  
  if(mo_count > 0) {
    return("Strength with Malodour")
  }
  
  # Par d√©faut, test de force (Strength)
  return("Strength")
}


# ===== BOUCLE PRINCIPALE COMPL√àTE MODIFI√âE =====
for (file_path in excel_files) {
  file_basename <- basename(file_path)
  source_name <- tools::file_path_sans_ext(file_basename)
  
  if(is_file_already_processed(file_path, tracking_data)) {
    message("\n=== FICHIER D√âJ√Ä TRAIT√â (SKIP): ", file_basename, " ===")
    files_skipped <- files_skipped + 1
    next
  }
  
  message("\n=== TRAITEMENT NOUVEAU FICHIER: ", file_basename, " ===")
  files_new <- files_new + 1
  
  # Lecture et validation
  sheet_names <- tryCatch({
    excel_sheets(file_path)
  }, error = function(e) {
    log_probleme("ERREUR_LECTURE", paste("Impossible de lire les onglets:", e$message), file_path)
    tracking_data <<- update_tracking(file_path, "ERREUR_LECTURE", NA, tracking_data)
    return(NULL)
  })
  
  if(is.null(sheet_names)) next
  
  if(!"Results" %in% sheet_names) {
    log_probleme("ONGLET_MANQUANT", "Onglet 'Results' manquant", file_path)
    tracking_data <- update_tracking(file_path, "ONGLET_MANQUANT", NA, tracking_data)
    next
  }
  
  # Lecture des donn√©es
  file_data <- tryCatch({
    read_excel(file_path, sheet = "Results") %>%
      mutate(SourceFile = basename(file_path))
  }, error = function(e) {
    log_probleme("ERREUR_LECTURE_RESULTS", paste("Erreur lecture Results:", e$message), file_path)
    tracking_data <<- update_tracking(file_path, "ERREUR_LECTURE_RESULTS", NA, tracking_data)
    return(NULL)
  })
  
  if(is.null(file_data)) next
  
  # Validation de l'unicit√© du trial
  tryCatch({
    n_trials <- n_distinct(file_data$TrialName)
    
    if (n_trials != 1) {
      issue_msg <- paste("MULTIPLE TRIALNAMES (", n_trials, 
                         ") | Fichier:", basename(file_path))
      
      data_issues_log[[length(data_issues_log) + 1]] <- issue_msg
      tracking_data <- update_tracking(file_path, "MULTIPLE_TRIALNAMES", 
                                       nrow(file_data), tracking_data)
      next
    } else {
      trial_name <- unique(file_data$TrialName)
    }
    
    # Validation de la coh√©rence des donn√©es
    consistency_issues <- validate_data_consistency(file_data)
    
    if(length(consistency_issues) > 0) {
      walk(consistency_issues, ~log_probleme("COHERENCE", .x, file_path))
    }
    
    # Pr√©paration et nettoyage des donn√©es
    df <- file_data %>%
      mutate(Value = suppressWarnings(as.numeric(gsub(",", ".", Value)))) %>%
      select(-any_of("NR")) %>%
      mutate(JudgeStatus = "conserved")
    
    # Stockage des donn√©es brutes
    all_raw_data[[basename(file_path)]] <- df
    
    # Segmentation pour analyse
    segments <- df %>%
      group_by(AttributeName, NomFonction) %>%
      group_split()
    
    message("Nombre de segments dans ce fichier: ", length(segments))
    
    # ===== D√âTERMINATION DU TYPE DE TEST POUR LE FICHIER =====
    file_test_type <- determine_test_type(segments)
    message("Type de test d√©tect√© pour le fichier: ", file_test_type)
    
  }, error = function(e) {
    log_probleme("ERREUR_TRAITEMENT", paste("Erreur g√©n√©rale:", e$message), file_path)
    tracking_data <- update_tracking(file_path, "ERREUR_TRAITEMENT", NA, tracking_data)
    next
  })
  
  # V√©rification des segments
  verification_results <- map(segments, verify_segments)
  
  # Logging des probl√®mes d√©tect√©s
  for(i in seq_along(verification_results)) {
    res <- verification_results[[i]]
    seg <- segments[[i]]
    seg_name <- paste(seg$AttributeName[1], seg$NomFonction[1], sep = " - ")
    
    if(!isTRUE(res$MinJudgesOK)) {
      issue_msg <- paste("TROP PEU DE JUGES (", res$Judges, "/3) | Segment:", seg_name)
      data_issues_log[[length(data_issues_log) + 1]] <- issue_msg
    }
    
    if(!isTRUE(res$MinProductsOK)) {
      issue_msg <- paste("TROP PEU DE PRODUITS (", res$Products, "/2) | Segment:", seg_name)
      data_issues_log[[length(data_issues_log) + 1]] <- issue_msg
    }
    
    if(res$OutOfRange > 0) {
      issue_msg <- paste("VALEURS HORS LIMITES (", res$OutOfRange, ") | Segment:", seg_name)
      data_issues_log[[length(data_issues_log) + 1]] <- issue_msg
    }
  }
  
  # Traitement adaptatif des segments
  segments_processed <- list()
  
  for (i in seq_along(segments)) {
    seg_name <- paste(segments[[i]]$AttributeName[1], segments[[i]]$NomFonction[1], sep = " - ")
    seg_verif <- verification_results[[i]]
    
    is_triangular <- file_test_type == "Triangular"
    
    if(!isTRUE(is_triangular) && 
       (!isTRUE(seg_verif$MinProductsOK) || !isTRUE(seg_verif$MinJudgesOK))) {
      next
    }
    
    if (is_triangular) {
      message("Application test TRIANGULAIRE: ", seg_name)
      result <- list(
        segment = segments[[i]],
        removed_judges = character(0),
        n_initial = n_distinct(segments[[i]]$CJ),
        n_final = n_distinct(segments[[i]]$CJ)
      )
      
    } else if (file_test_type == "Proximity") {
      message("Application test PROXIMITE: ", seg_name)
      result <- handle_proximity_test(segments[[i]])
      
    } else if (file_test_type == "Strength with Malodour") {
      message("Application test MO (odeur corporell): ", seg_name)
      result <- analyze_judges_iterative(segments[[i]])
      
    } else {
      message("Application test STANDARD: ", seg_name)
      result <- analyze_judges_iterative(segments[[i]])
    }
    
    segments_processed[[i]] <- result$segment
    
    if (length(result$removed_judges) > 0) {
      judge_info <- data.frame(
        File = basename(file_path),
        Segment = seg_name,
        SegmentIndex = i,
        RemovedJudges = paste(result$removed_judges, collapse = ", "),
        JudgesInitial = result$n_initial,
        JudgesFinal = result$n_final,
        stringsAsFactors = FALSE
      )
      judge_removal_info[[length(judge_removal_info) + 1]] <- judge_info
    }
    
    message("Juges initiaux: ", result$n_initial,
            " | Juges finaux: ", result$n_final,
            " | Juges retir√©s: ", ifelse(length(result$removed_judges) > 0,
                                         paste(result$removed_judges, collapse = ", "), "aucun"))
  }
  
  # Consolidation des segments trait√©s
  final_data <- bind_rows(segments_processed)
  
  # ===== CORRECTION DANS LA BOUCLE PRINCIPALE =====
  # Analyse diff√©rentielle des produits avec le type de test du fichier
  triangular_results <- process_triangular_segments(segments_processed, file_path, file_test_type)
  
  # Correction : filtrer correctement les segments non-triangulaires
  non_triangular_segments <- list()
  for(i in seq_along(segments_processed)) {
    seg <- segments_processed[[i]]
    if(!is.null(seg) && nrow(seg) > 0) {
      # Si ce n'est pas un test triangulaire au niveau du fichier, inclure le segment
      if(file_test_type != "Triangular") {
        non_triangular_segments[[length(non_triangular_segments) + 1]] <- seg
      }
    }
  }
  
  standard_results <- map2(non_triangular_segments, seq_along(non_triangular_segments), 
                           ~analyze_products(.x, .y, file_path, file_test_type)) %>%
    compact() %>%
    bind_rows()
  
  # Consolidation finale des r√©sultats
  file_results <- bind_rows(
    triangular_results,
    standard_results
  )
  
  
  if (nrow(file_results) > 0) {
    all_results[[basename(file_path)]] <- file_results
    print(file_results)
  }
  
  # Cr√©ation de la table de tracking des juges pour ce fichier
  
  
  # ===== SAUVEGARDE DANS LES BASES DE DONN√âES (ORDRE CORRIG√â) =====
  
  # 1. Sauvegarder les r√©sultats avec le type de test du fichier
  if(exists("file_results") && nrow(file_results) > 0) {
    if(save_results_to_db(file_results, source_name, file_test_type)) {
      message("‚úÖ R√©sultats sauvegard√©s dans SA_RESULTS_DATA (", file_test_type, ")")
    }
  }
  
  
  # 3. Pr√©parer les informations des juges retir√©s pour ce fichier
  file_judge_changes_for_db <- judge_removal_info %>% 
    keep(~ .x$File == basename(file_path)) %>%
    map_df(~ .x)
  
  # 4. Sauvegarder les donn√©es brutes AVEC le statut des juges (APR√àS traitement)
  if(save_raw_data_with_judge_status(file_data, source_name, file_judge_changes_for_db)) {
    message("‚úÖ Donn√©es brutes sauvegard√©es dans SA_RAW_DATA avec statut juges")
  }
  
  # 5. Cr√©er les enregistrements complets pour l'application Shiny
  if(save_product_info_complete(file_data, source_name)) {
    message("‚úÖ Product_Info complet cr√©√© avec champs vides")
  }
  
  if(save_test_info_complete(file_data, source_name)) {
    message("‚úÖ Test_Info complet cr√©√© avec champs vides")
  }
  
  
  # Mise √† jour du tracking
  tracking_data <- update_tracking(file_path, "SUCCES", nrow(file_data), tracking_data)
  files_processed <- files_processed + 1
  
  # G√©n√©ration des fichiers Excel individuels
  current_file <- as.character(file_path)
  
  raw_data_with_status <- file_data %>%
    mutate(
      JudgeStatus = "conserved",
      SourceFile = basename(current_file)
    )
  
  file_judge_changes <- judge_removal_info %>% 
    keep(~ .x$File == basename(current_file)) %>%
    map_df(~ .x)
  
  if(nrow(file_judge_changes) > 0) {
    raw_data_with_status <- raw_data_with_status %>% 
      mutate(JudgeStatus = case_when(
        CJ %in% unlist(strsplit(file_judge_changes$RemovedJudges, ", ")) &
          paste(AttributeName, NomFonction, sep = " - ") %in% file_judge_changes$Segment ~ "removed",
        TRUE ~ JudgeStatus
      ))
  }
  
  # G√©n√©ration du fichier de sortie individuel
  output_file_name <- paste0("ANALYSE_", tools::file_path_sans_ext(basename(current_file)), ".xlsx")
  output_file_path <- file.path(output_base_dir, output_file_name)
  
  tryCatch({
    # Pr√©parer les donn√©es pour l'export
    export_data <- list()
    
    # 1. Donn√©es brutes avec statut des juges
    export_data$"Donnees_Brutes" <- raw_data_with_status %>%
      select(TrialName, CJ, ProductName, AttributeName, NomFonction, Value, JudgeStatus, SourceFile) %>%
      arrange(AttributeName, NomFonction, CJ, ProductName)
    
    # 2. R√©sultats d'analyse
    if(exists("file_results") && nrow(file_results) > 0) {
      export_data$"Resultats_Analyse" <- file_results
    } else {
      export_data$"Resultats_Analyse" <- tibble(
        Message = "Aucun r√©sultat g√©n√©r√© pour ce fichier",
        Raison = "Donn√©es insuffisantes ou erreur de traitement",
        Timestamp = Sys.time()
      )
    }
    
    # 3. Tracking des juges pour ce fichier
    if(exists("judge_tracking_table") && nrow(judge_tracking_table) > 0) {
      export_data$"Tracking_Juges" <- judge_tracking_table
    } else {
      export_data$"Tracking_Juges" <- tibble(
        Message = "Aucun tracking de juges disponible",
        Timestamp = Sys.time()
      )
    }
    
    # 4. Informations sur les juges retir√©s
    if(nrow(file_judge_changes) > 0) {
      export_data$"Juges_Retires" <- file_judge_changes
    } else {
      export_data$"Juges_Retires" <- tibble(
        Message = "Aucun juge retir√© pour ce fichier",
        Timestamp = Sys.time()
      )
    }
    
    # 5. R√©sum√© du fichier
    file_summary <- tibble(
      Fichier_Source = basename(current_file),
      Trial_Name = trial_name,
      Date_Traitement = Sys.time(),
      Nb_Lignes_Brutes = nrow(file_data),
      Nb_Segments = length(segments),
      Nb_Juges_Total = n_distinct(file_data$CJ),
      Nb_Produits_Total = n_distinct(file_data$ProductName),
      Nb_Attributs_Total = n_distinct(file_data$AttributeName),
      Type_Test_Detecte = file_test_type,
      Statut_Traitement = "SUCCES"
    )
    
    export_data$"Resume_Fichier" <- file_summary
    
    # 6. Log des probl√®mes pour ce fichier (si applicable)
    file_issues <- data_issues_log[str_detect(data_issues_log, basename(current_file))]
    if(length(file_issues) > 0) {
      export_data$"Problemes_Detectes" <- tibble(
        Probleme = file_issues,
        Timestamp = Sys.time()
      )
    }
    
    # √âcriture du fichier Excel
    write_xlsx(export_data, output_file_path)
    message("üìÑ Fichier individuel g√©n√©r√©: ", output_file_path)
    
  }, error = function(e) {
    message("‚ùå ERREUR g√©n√©ration fichier individuel: ", e$message)
    
    # Cr√©er un fichier d'erreur minimal
    error_data <- list(
      "ERREUR" = tibble(
        Fichier = basename(current_file),
        Erreur = e$message,
        Timestamp = Sys.time(),
        Message = "√âchec de g√©n√©ration du rapport complet"
      )
    )
    
    tryCatch({
      write_xlsx(error_data, output_file_path)
      message("üìÑ Fichier d'erreur cr√©√©: ", output_file_path)
    }, error = function(e2) {
      message("‚ùå Impossible de cr√©er m√™me le fichier d'erreur: ", e2$message)
    })
  })
}

message("\n=== G√âN√âRATION DU TRACKING GLOBAL DES JUGES ===")

if(length(judge_removal_info) > 0 && length(all_raw_data) > 0) {
  tryCatch({
    # Consolidation de toutes les informations
    all_judge_info_df <- bind_rows(judge_removal_info)
    all_raw_data_df <- bind_rows(all_raw_data)
    
    message("Donn√©es consolid√©es : ", nrow(all_raw_data_df), " lignes brutes, ", 
            nrow(all_judge_info_df), " informations de retrait")
    
    # ‚úÖ CR√âATION DE LA TABLE GLOBALE OPTIMIS√âE
    global_judge_tracking <- create_judge_tracking_table(all_judge_info_df, all_raw_data_df)
    
    if(nrow(global_judge_tracking) > 0) {
      # ‚úÖ SAUVEGARDE GLOBALE
      if(save_judges_to_db(global_judge_tracking, "GLOBAL")) {
        message("‚úÖ Tracking global des juges sauvegard√© dans SA_JUDGES")
        message("   ‚Üí ", nrow(global_judge_tracking), " juges uniques track√©s")
      }
    } else {
      message("‚ö†Ô∏è Aucune donn√©e de tracking global g√©n√©r√©e")
    }
    
  }, error = function(e) {
    message("‚ùå Erreur g√©n√©ration tracking global des juges : ", e$message)
  })
} else {
  message("‚ö†Ô∏è Pas assez de donn√©es pour g√©n√©rer le tracking global des juges")
  message("   Judge removal info : ", length(judge_removal_info), " entr√©es")
  message("   Raw data : ", length(all_raw_data), " fichiers")
}

# ===== G√âN√âRATION DU FICHIER CONSOLID√â =====
message("\n=== G√âN√âRATION DU FICHIER CONSOLID√â ===")

# ===== G√âN√âRATION DU FICHIER CONSOLID√â GLOBAL =====
message("\n=== G√âN√âRATION DU FICHIER CONSOLID√â GLOBAL ===")

consolidated_file_path <- file.path(output_base_dir, "ANALYSE_CONSOLIDEE_GLOBALE.xlsx")

tryCatch({
  consolidated_data <- list()
  
  # 1. R√©sum√© global de l'analyse
  global_summary <- tibble(
    Date_Analyse = Sys.time(),
    Fichiers_Detectes = length(excel_files),
    Fichiers_Deja_Traites = files_skipped,
    Nouveaux_Fichiers = files_new,
    Fichiers_Traites_Succes = files_processed,
    Fichiers_En_Erreur = files_new - files_processed,
    Taux_Succes = round((files_processed / files_new) * 100, 1),
    Dossier_Source = raw_data_dir,
    Dossier_Sortie = output_base_dir
  )
  
  consolidated_data$"Resume_Global" <- global_summary
  
  # 2. Consolidation de tous les r√©sultats
  if(length(all_results) > 0) {
    all_results_df <- map_dfr(all_results, ~.x, .id = "Fichier_Source")
    consolidated_data$"Tous_Resultats" <- all_results_df
    
    # ===== G√âN√âRATION DU FICHIER CONSOLID√â GLOBAL (SUITE) =====
    # Statistiques par type de test
    test_stats <- all_results_df %>%
      group_by(TESTTYPE) %>%
      summarise(
        Nb_Tests = n(),
        Nb_Fichiers = n_distinct(Fichier_Source),
        .groups = 'drop'
      )
    
    consolidated_data$"Stats_Types_Tests" <- test_stats
    
    # Statistiques par produit (pour tests non-triangulaires)
    if("PRODUCT" %in% names(all_results_df)) {
      product_stats <- all_results_df %>%
        filter(!is.na(PRODUCT)) %>%
        group_by(PRODUCT) %>%
        summarise(
          Nb_Occurrences = n(),
          Nb_Fichiers = n_distinct(Fichier_Source),
          Moyenne_Score = round(mean(MEAN, na.rm = TRUE), 2),
          .groups = 'drop'
        ) %>%
        arrange(desc(Nb_Occurrences))
      
      consolidated_data$"Stats_Produits" <- product_stats
    }
    
    # Statistiques des tests triangulaires
    triangular_tests <- all_results_df %>%
      filter(TESTTYPE == "Triangular") %>%
      select(Fichier_Source, IDTEST, REFERENCE, CANDIDATE, N, CORRECT, P_VALUE, DECISION)
    
    if(nrow(triangular_tests) > 0) {
      consolidated_data$"Tests_Triangulaires" <- triangular_tests
    }
    
  } else {
    consolidated_data$"Tous_Resultats" <- tibble(
      Message = "Aucun r√©sultat d'analyse disponible",
      Timestamp = Sys.time()
    )
  }
  
  # 3. Consolidation du tracking des juges
  if(length(judge_removal_info) > 0) {
    all_judge_info_df <- bind_rows(judge_removal_info)
    consolidated_data$"Tracking_Juges_Global" <- all_judge_info_df
    
    # Statistiques des juges retir√©s
    judge_stats <- all_judge_info_df %>%
      group_by(RemovedJudges) %>%
      summarise(
        Nb_Retraits = n(),
        Fichiers_Concernes = n_distinct(File),
        .groups = 'drop'
      ) %>%
      separate_rows(RemovedJudges, sep = ", ") %>%
      filter(RemovedJudges != "" & !is.na(RemovedJudges)) %>%
      group_by(RemovedJudges) %>%
      summarise(
        Total_Retraits = sum(Nb_Retraits),
        Total_Fichiers = sum(Fichiers_Concernes),
        .groups = 'drop'
      ) %>%
      arrange(desc(Total_Retraits))
    
    consolidated_data$"Stats_Juges_Retires" <- judge_stats
  } else {
    consolidated_data$"Tracking_Juges_Global" <- tibble(
      Message = "Aucun juge retir√© dans cette analyse",
      Timestamp = Sys.time()
    )
  }
  
  # 4. Consolidation des donn√©es brutes
  if(length(all_raw_data) > 0) {
    all_raw_data_df <- bind_rows(all_raw_data)
    
    # Statistiques globales des donn√©es brutes
    raw_data_stats <- all_raw_data_df %>%
      group_by(SourceFile) %>%
      summarise(
        Nb_Lignes = n(),
        Nb_Juges = n_distinct(CJ),
        Nb_Produits = n_distinct(ProductName),
        Nb_Attributs = n_distinct(AttributeName),
        Nb_Fonctions = n_distinct(NomFonction),
        Valeur_Min = min(Value, na.rm = TRUE),
        Valeur_Max = max(Value, na.rm = TRUE),
        Valeur_Moyenne = round(mean(Value, na.rm = TRUE), 2),
        Nb_Valeurs_Manquantes = sum(is.na(Value)),
        .groups = 'drop'
      )
    
    consolidated_data$"Stats_Donnees_Brutes" <- raw_data_stats
  }
  
  # 5. Log des probl√®mes d√©tect√©s
  if(length(data_issues_log) > 0) {
    issues_df <- tibble(
      Probleme = unlist(data_issues_log),
      Timestamp = Sys.time()
    ) %>%
      separate(Probleme, into = c("Type", "Details"), sep = "] ", extra = "merge") %>%
      mutate(Type = str_remove(Type, "^\\["))
    
    consolidated_data$"Problemes_Detectes" <- issues_df
    
    # R√©sum√© des types de probl√®mes
    problem_summary <- issues_df %>%
      group_by(Type) %>%
      summarise(
        Nb_Occurrences = n(),
        .groups = 'drop'
      ) %>%
      arrange(desc(Nb_Occurrences))
    
    consolidated_data$"Resume_Problemes" <- problem_summary
  }
  
  # 6. Donn√©es de tracking des fichiers
  consolidated_data$"Tracking_Fichiers" <- tracking_data %>%
    arrange(desc(Date_Traitement))
  
  # √âcriture du fichier consolid√©
  write_xlsx(consolidated_data, consolidated_file_path)
  message("üìä Fichier consolid√© global g√©n√©r√©: ", consolidated_file_path)
  
}, error = function(e) {
  message("‚ùå ERREUR g√©n√©ration fichier consolid√©: ", e$message)
  
  # Cr√©er un fichier d'erreur minimal
  error_consolidated <- list(
    "ERREUR_CONSOLIDATION" = tibble(
      Erreur = e$message,
      Timestamp = Sys.time(),
      Message = "√âchec de g√©n√©ration du fichier consolid√©",
      Nb_Fichiers_Traites = files_processed
    )
  )
  
  tryCatch({
    write_xlsx(error_consolidated, consolidated_file_path)
    message("üìä Fichier d'erreur consolid√© cr√©√©: ", consolidated_file_path)
  }, error = function(e2) {
    message("‚ùå Impossible de cr√©er le fichier d'erreur consolid√©: ", e2$message)
  })
})

# ===== SAUVEGARDE FINALE DU TRACKING =====
save_tracking_data(tracking_data)

# ===== R√âSUM√â FINAL =====
message("\n", paste(rep("=", 60), collapse = ""))
message("ANALYSE SENSO TERMIN√âE - R√âSUM√â FINAL")
message(paste(rep("=", 60), collapse = ""))
message("üìÅ Dossier source: ", raw_data_dir)
message("üìÅ Dossier sortie: ", output_base_dir)
message("üìä Fichiers Excel d√©tect√©s: ", length(excel_files))
message("‚è≠Ô∏è  Fichiers d√©j√† trait√©s (skipp√©s): ", files_skipped)
message("üÜï Nouveaux fichiers d√©tect√©s: ", files_new)
message("‚úÖ Fichiers trait√©s avec succ√®s: ", files_processed)
message("‚ùå Fichiers en erreur: ", files_new - files_processed)

if(files_new > 0) {
  message("üìà Taux de succ√®s: ", round((files_processed / files_new) * 100, 1), "%")
}

message("üóÉÔ∏è  R√©sultats d'analyse g√©n√©r√©s: ", length(all_results))

if(length(data_issues_log) > 0) {
  message("‚ö†Ô∏è  Probl√®mes d√©tect√©s: ", length(data_issues_log))
  message("   Consultez les fichiers de sortie pour plus de d√©tails")
}

# Statistiques des bases de donn√©es
# ===== R√âSUM√â FINAL MODIFI√â =====
# Dans la section finale, remplacer :
message("\nüìä SAUVEGARDE DANS LES BASES DE DONN√âES:")
message("   ‚Ä¢ SA_RAW_DATA: Donn√©es brutes sauvegard√©es")
message("   ‚Ä¢ SA_RESULTS_DATA: R√©sultats d'analyse sauvegard√©s dans tables sp√©cialis√©es:")
message("     - strengthandmo_results: Tests Strength et Strength with Malodour")
message("     - proximity_results: Tests de proximit√©") 
message("     - triangulaire_results: Tests triangulaires")
message("   ‚Ä¢ SA_JUDGES: Tracking des juges sauvegard√©")
message("   ‚Ä¢ SA_METADATA: M√©tadonn√©es sauvegard√©es:")
message("     - product_info: Informations produits")
message("     - test_info: Informations tests")
message("     - databrute: Couples m√©tadonn√©es")


message("\nüìÑ FICHIERS G√âN√âR√âS:")
message("   ‚Ä¢ Fichiers individuels: ", files_processed, " fichiers ANALYSE_*.xlsx")
message("   ‚Ä¢ Fichier consolid√©: ANALYSE_CONSOLIDEE_GLOBALE.xlsx")
message("   ‚Ä¢ Fichier de tracking: TRACKING_FICHIERS.xlsx")

message("\nüïê Analyse termin√©e: ", Sys.time())
message(paste(rep("=", 60), collapse = ""))

# ===== NETTOYAGE FINAL =====
# Fermer toutes les connexions ouvertes (s√©curit√©)
tryCatch({
  # Nettoyer l'environnement des gros objets
  if(exists("all_raw_data_df")) rm(all_raw_data_df)
  if(exists("all_results_df")) rm(all_results_df)
  
  # Forcer le garbage collection
  gc()
  
  message("üßπ Nettoyage de l'environnement termin√©")
}, error = function(e) {
  message("‚ö†Ô∏è  Erreur lors du nettoyage: ", e$message)
})

message("\nüéâ PROCESSUS D'ANALYSE SENSO COMPL√àTEMENT TERMIN√â! üéâ")
